<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Load Balancer</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet">
    <link href="../../common/styles.css" rel="stylesheet">
    <script>
        // Function to include an external HTML file
        function loadHTML(file, elementId) {
            fetch(file)
                .then(response => response.text())
                .then(data => document.getElementById(elementId).innerHTML = data)
                .catch(error => console.error('Error loading HTML:', error));
        }
    </script>
</head>

<body onload="loadHTML('../../common/navbar.html', 'navbar-placeholder')">
    <!-- Navbar Placeholder -->
    <div id="navbar-placeholder"></div>

    <div class="container">

        <div class="content">
            <h3 class="section-title">What is load balancing</h3>
            <p>Load balancing is the process of distributing incoming network or application traffic across multiple servers to ensure no single server becomes overwhelmed. 
                <br>This helps in achieving several key objectives:
                <ul>
                    <li><b>Improved Performance: </b>By spreading the load, each server handles a smaller portion of the traffic, which can improve response times and overall system performance.</li>
                    <li><b>Increased Availability: </b>If one server fails, the load balancer can redirect traffic to other healthy servers, ensuring that the service remains available.</li>
                    <li><b>Scalability: </b>Load balancing allows the system to handle increased traffic by adding more servers to the pool and distributing the load among them.</li>
                    <li><b>Efficient Resource Utilization: </b>It ensures that server resources are used efficiently, preventing any single server from becoming a bottleneck.</li>
                </ul>
                <img src="../../images/lb.PNG" alt="lb" style="display: block; margin: auto;">
            </p>
            <br>
            <h3 class="section-title">Load Balancer Placement</h3>
                <p>Typically, load balancers are positioned between clients and servers, managing the traffic flow from clients to servers and back. However, load balancers can also be strategically placed at various points within a server infrastructure to optimize traffic distribution among different server types. 
                    Here’s how load balancers can be utilized across the three main types of servers:</p>

                <ul>
                    <li><strong>Between End Users and Web Servers/Application Gateway:</strong> Place load balancers between the application’s end users and the web servers or application gateway to manage incoming traffic and ensure even distribution across multiple web servers.</li>
                    <li><strong>Between Web Servers and Application Servers:</strong> Position load balancers between web servers and application servers that handle business or application logic to balance the load among application servers effectively.</li>
                    <li><strong>Between Application Servers and Database Servers:</strong> Use load balancers between application servers and database servers to distribute database queries and ensure consistent performance and availability.</li>
                </ul>
                <img src="../../images/lb-1.PNG" alt="lb" style="display: block; margin: auto; width: 80%;">
            <br>
            <h3 class="section-title">Services offered by load balancers</h3>
                <p>Load balancers offer a variety of services to ensure efficient distribution of traffic and maintain high availability and performance in distributed systems. Here’s a comprehensive list of services typically offered by load balancers</p>

                
                    <ul>
                        <li><strong>Traffic Distribution:</strong> Load balancers evenly distribute incoming traffic across multiple servers to prevent any single server from becoming overloaded. This helps improve overall system performance and responsiveness.</li>
                        <li><strong>High Availability:</strong> By monitoring the health of servers and rerouting traffic away from servers that are down or underperforming, load balancers help maintain uninterrupted service availability.</li>                        
                        <li><strong>Scalability:</strong> Load balancers support scaling by dynamically distributing traffic to additional servers as needed, accommodating increased load and ensuring smooth operation during traffic spikes.</li>
                        <li><strong>Session Persistence:</strong> Also known as sticky sessions, this feature ensures that a user's session is consistently routed to the same server, maintaining session state and improving user experience.</li>                    
                        <li><strong>SSL/TLS Offloading:</strong> Load balancers can handle SSL/TLS encryption and decryption tasks, offloading this resource-intensive process from backend servers and improving overall performance.</li>                        
                        <li><strong>Health Checks:</strong> Load balancers regularly perform health checks on servers to ensure they are operating correctly. Traffic is only directed to healthy servers, and problematic servers are temporarily removed from the pool.</li>               
                        <li><strong>Content-Based Routing:</strong> Load balancers can route traffic based on content types or URL paths, directing requests to appropriate servers or services based on the specific content being requested.</li>
                        <li><strong>Geographic Load Balancing:</strong> Distribute traffic across multiple geographic locations or data centers to reduce latency and provide a better user experience by serving requests from the nearest location.</li>
                        <li><strong>Rate Limiting:</strong> Implement policies to control the rate of incoming requests to prevent abuse and ensure fair usage across all users.</li>
                        <li><strong>Application Layer Security:</strong> Some load balancers offer built-in security features, such as Web Application Firewall (WAF) integration, to protect against common web threats and attacks.</li>
                    </ul>
            

            <h3 class="section-title">Global Load Balancing</h3>
                <p>Global load balancing involves distributing traffic across multiple geographic locations or data centers. It ensures that user requests are routed to the closest or most efficient data center based on factors such as latency, server health, and load conditions.</p>
                    
                <h6>Examples:</h6>
                <ul>
                    <li><strong>Content Delivery Networks (CDNs):</strong> Services like Cloudflare and Akamai use global load balancing to route user requests to the nearest edge server, improving content delivery speed and reducing latency.</li>
                    <li><strong>Global DNS Load Balancers:</strong> Providers like AWS Route 53 or Google Cloud DNS use geographic routing to direct traffic to data centers around the world based on the user's location.</li>
                    <li><strong>Multi-Region Cloud Applications:</strong> Applications deployed across multiple regions (e.g., AWS Elastic Load Balancer with multiple regional endpoints) use global load balancing to distribute traffic across these regions for better performance and redundancy.</li>
                </ul>
            

            <h3 class="section-title">Local Load Balancing</h3>
                <p>Local load balancing distributes traffic within a single geographic location or data center. It ensures even distribution of traffic among servers within a specific region or data center to balance the load and optimize resource utilization.</p>
                
                <h6>Examples:</h6>
                <ul>
                    <li><strong>In-Data Center Load Balancers:</strong> Services like HAProxy or Nginx used within a data center to balance requests across multiple application servers or web servers.</li>
                    <li><strong>Internal Network Load Balancers:</strong> Tools like Microsoft Azure Load Balancer that handle traffic distribution among virtual machines within a single region or data center.</li>
                    <li><strong>Database Load Balancers:</strong> Balancers used within a specific data center to distribute database queries among multiple database servers to ensure optimal performance and availability.</li>
                </ul>
            
            <h3 class="section-title">Global vs Local Load Balancing</h5>
                <table>
                    <thead>
                        <tr>
                            <th>Aspect</th>
                            <th>Global Load Balancing</th>
                            <th>Local Load Balancing</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>Scope</strong></td>
                            <td>Covers multiple geographic locations or data centers.</td>
                            <td>Confined to a single location or data center.</td>
                        </tr>
                        <tr>
                            <td><strong>Use Case</strong></td>
                            <td>Used for applications with a global user base to reduce latency and improve performance.</td>
                            <td>Used to optimize resource utilization and manage traffic within a specific region.</td>
                        </tr>
                        <tr>
                            <td><strong>Routing Decision</strong></td>
                            <td>Considers geographic location and latency.</td>
                            <td>Focuses on server health and load within a single data center.</td>
                        </tr>
                    </tbody>
                </table>
            <br>

            <h3 class="section-title">Load Balancing Algorithms</h5>
            <table>
                <thead>
                    <tr>
                        <th>Algorithm</th>
                        <th>Description</th>
                        <th>Use Case</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Round Robin</strong></td>
                        <td>Distributes requests sequentially across all available servers, cycling through the list repeatedly.</td>
                        <td>Simple scenarios where each server has similar capacity and there is no need for session persistence.</td>
                    </tr>
                    <tr>
                        <td><strong>Least Connections</strong></td>
                        <td>Routes traffic to the server with the fewest active connections. This helps to balance the load based on current server usage.</td>
                        <td>Environments where servers have varying capacities or workloads, providing more dynamic load distribution.</td>
                    </tr>
                    <tr>
                        <td><strong>Least Response Time</strong></td>
                        <td>Directs requests to the server with the lowest response time, improving performance by prioritizing faster servers.</td>
                        <td>Applications where response time is critical, such as real-time services or high-performance computing.</td>
                    </tr>
                    <tr>
                        <td><strong>Weighted Round Robin</strong></td>
                        <td>Similar to Round Robin, but allows servers to be assigned weights based on their capacity or performance. Requests are distributed proportionally to these weights.</td>
                        <td>Scenarios where servers have different capabilities, ensuring that more powerful servers handle a larger share of the load.</td>
                    </tr>
                    <tr>
                        <td><strong>Weighted Least Connections</strong></td>
                        <td>Combines weights with the Least Connections algorithm. Servers are assigned weights, and traffic is routed to servers with the fewest connections, considering their weight.</td>
                        <td>When servers have different capacities and varying loads, allowing for a balanced distribution based on both server performance and current connections.</td>
                    </tr>
                    <tr>
                        <td><strong>IP Hash</strong></td>
                        <td>Routes requests based on a hash of the client’s IP address. This ensures that a specific client consistently reaches the same server, which can be useful for session persistence.</td>
                        <td>Applications requiring session persistence, where users need to interact with the same server to maintain state.</td>
                    </tr>
                    <tr>
                        <td><strong>Session Persistence (Sticky Sessions)</strong></td>
                        <td>Keeps track of sessions and directs requests from the same user to the same server. This can be implemented using various techniques like cookies or session identifiers.</td>
                        <td>Applications where maintaining user sessions on the same server is critical, such as online shopping carts or login systems.</td>
                    </tr>
                    <tr>
                        <td><strong>Least Bandwidth</strong></td>
                        <td>Directs traffic to the server with the least amount of bandwidth usage, helping to balance the load based on network throughput.</td>
                        <td>Environments where managing network bandwidth is important, such as media streaming or high-traffic websites.</td>
                    </tr>
                    <tr>
                        <td><strong>Least Response Time with Weighted Distribution</strong></td>
                        <td>Routes requests based on the lowest response time, adjusted by server weights. This combines performance metrics with server capacity.</td>
                        <td>Complex applications needing both performance optimization and resource balancing.</td>
                    </tr>
                </tbody>
            </table>
            <br>
            <h3 class="section-title">Stateful Load Balancers</h3>
                <p>Stateful load balancers maintain session information about clients and their interactions. They keep track of client state and route requests based on this information to ensure continuity of the user session.</p>

                <h6>Characteristics:</h6>
                <ul>
                    <li><strong>Session Persistence:</strong> Ensures that a client consistently interacts with the same server, which is useful for applications that require session consistency.</li>
                    <li><strong>Session Tracking:</strong> Keeps track of client sessions and state information, often using cookies or session identifiers.</li>
                    <li><strong>Complexity:</strong> Typically more complex to manage, as it requires maintaining session information and dealing with state synchronization.</li>
                    <li><strong>Example:</strong> Applications where users need to remain connected to the same server, such as online shopping carts or authentication systems.</li>
                </ul>
                <img src="../../images/lb-2.PNG" alt="lb" style="display: block; margin: auto; width: 40%;">
            <br>
    
            <h3 class="section-title">Stateless Load Balancers</h3>
                <p>Stateless load balancers do not retain any information about client sessions. They distribute requests to servers without considering any previous interactions or states.</p>

                <h6>Characteristics:</h6>
                <ul>
                    <li><strong>No Session Persistence:</strong> Each request is handled independently, and there is no need for session continuity or state management.</li>
                    <li><strong>Simplicity:</strong> Generally simpler and more scalable, as they do not need to maintain or synchronize session information.</li>
                    <li><strong>Resilience:</strong> More resilient to server failures, as each request is handled in isolation without relying on past interactions.</li>
                    <li><strong>Example:</strong> Stateless applications where sessions do not need to be preserved, such as public web content or RESTful APIs.</li>
                </ul>
                <img src="../../images/lb-3.PNG" alt="lb" style="display: block; margin: auto; width: 40%;">
            <br>
            <h3 class="section-title">Layerwise Load Balancers</h3>
                <h6>Application Load Balancers</h6>
                <ul>
                    <li>AWS Application Load Balancer (ALB)</li>
                    <li>NGINX</li>
                </ul>
                <h6>Network Load Balancers</h6>
                <ul>
                    <li>AWS Network Load Balancer (NLB)</li>
                    <li>Azure Load Balancer</li>
                </ul>
                <h6>DNS-Based Load Balancers</h6>
                <ul>
                    <li>AWS Route 53</li>
                    <li>Cloudflare Load Balancing</li>
                </ul>
            <br>
        </div>
    </div>

    <!-- Footer -->
    <div class="footer">
        <p>&copy; 2024 My Blog. All rights reserved.</p>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
</body>

</html>
